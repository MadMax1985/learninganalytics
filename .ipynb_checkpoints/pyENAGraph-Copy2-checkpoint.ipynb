{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "from rpy2 import robjects\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from heapq import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(rpy2.__version__)\n",
    "utils = importr('utils')\n",
    "print(utils.packageVersion(\"rENA\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input as Pandas Dataframe\n",
    "\n",
    "* Generate points rotade for each grupo of topicsID on dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas2ri.activate()\n",
    "rena = importr('rENA')\n",
    "posts = pd.read_excel('posts.xls', 'controle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = posts[posts['phaseId'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_topicId = []\n",
    "for i in range(0,len(posts['topicId'].unique())):\n",
    "    posts_topicId.append(posts[posts['topicId'] == posts['topicId'].unique()[i]])\n",
    "#posts_topicId[1][['topicId','postParentId']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ENA Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyset_list = []\n",
    "for post in posts_topicId:\n",
    "    accum =  rena.ena_accumulate_data( units = post[[\"postId\"]], conversation = post[[\"postId\"]], codes = post[[\"construction.intro\",\n",
    "       \"scope.intro\", \"maintenance.intro\", \"general.comments\",\n",
    "       \"construction.methods\", \"process.intro\", \"maintenance.management\",\n",
    "       \"process.stages\", \"design.quality\", \"requirements.methods\",\n",
    "       \"process.keyissues\", \"design.methods\", \"construction.languages\",\n",
    "       \"requirements.intro\", \"design.intro\"]],  weight_by = \"identity\", window_size_back = 1)\n",
    "    pyset_list.append(rena.ena_make_set(enadata = accum))\n",
    "len(pyset_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_list(pyset_list):\n",
    "    cos_distance_list = []\n",
    "    for pyset in pyset_list:\n",
    "        distance_topicID = []\n",
    "        for i in range(0,len(np.array(pyset['points.rotated']))):\n",
    "            distance_post = []\n",
    "            for j in range(i, len(np.array(pyset['points.rotated']))):\n",
    "                distance_post.append(1 - spatial.distance.cosine(np.array(pyset['points.rotated'])[i], np.array(pyset['points.rotated'])[j]))\n",
    "            distance_topicID.append(distance_post)\n",
    "        cos_distance_list.append(distance_topicID)\n",
    "    return(cos_distance_list)\n",
    "        \n",
    "distance_list = get_distance_list(pyset_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_implicit_edges(distance_list, limit):\n",
    "    edge_list = []\n",
    "    for similarity in distance_list:\n",
    "        topic_edge = []\n",
    "        for i in range(0,len(similarity)):\n",
    "            for j in range(0,len(similarity[i])):\n",
    "                if (abs(similarity[i][j]) >= limit):\n",
    "                    topic_edge.append((j+i, i))\n",
    "        edge_list.append(topic_edge)\n",
    "    return edge_list\n",
    "    \n",
    "implicit_edges = get_implicit_edges(distance_list, 0.90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explicit_edges(postList):\n",
    "    explicit_edges_lst = []\n",
    "    for forum in postList:\n",
    "        postParentId = forum['postParentId'].tolist()\n",
    "        postId = forum['postId'].tolist()\n",
    "        edge_list = []\n",
    "        for i in range(0,len(postParentId)):\n",
    "            if postParentId[i] in postId:\n",
    "                edge_list.append((i, postId.index(postParentId[i])))\n",
    "        explicit_edges_lst.append(edge_list)\n",
    "    return explicit_edges_lst\n",
    "        \n",
    "explicit_edges = get_explicit_edges(posts_topicId)\n",
    "#print(postParentId)\n",
    "#print(postId)\n",
    "#print(edge_list)\n",
    "#postId.index(postParentId[2])\n",
    "#explicit_edges[2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Identificar quem é o lider e o participante nos nós. (atribuir cores quando desenhar)\n",
    "#### Participante Verde, Líder Vermelho, inicial nó quadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roleList(posts_topicId):\n",
    "    liderLst = []\n",
    "    participanteLst = []\n",
    "    for forum in posts_topicId:\n",
    "        roleList = ((forum['UserRole (11- expert/part1, 12 - expert/part2,   21- participant/part1, 22- participant/part2)'] == 11) | \n",
    "                    (forum['UserRole (11- expert/part1, 12 - expert/part2,   21- participant/part1, 22- participant/part2)'] == 12)).tolist()\n",
    "        lider = []\n",
    "        participante = []\n",
    "        for i in range(0,len(roleList)):\n",
    "            if roleList[i] == True:\n",
    "                lider.append(i)\n",
    "            else:\n",
    "                participante.append(i)\n",
    "\n",
    "        liderLst.append(lider)\n",
    "        participanteLst.append(participante)\n",
    "    return (liderLst,participanteLst)\n",
    "\n",
    "liderLst, participanteLst = get_roleList(posts_topicId)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Loops in Implicit Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLoops(implicit_edges):\n",
    "    newImplicitEdges = []\n",
    "    for edgeList in implicit_edges:\n",
    "        newEdges = []\n",
    "        for i in range(0,len(edgeList)):\n",
    "            if edgeList[i][0] != edgeList[i][1]:\n",
    "                newEdges.append(edgeList[i])\n",
    "        newImplicitEdges.append(newEdges)\n",
    "                \n",
    "    return (newImplicitEdges)\n",
    "\n",
    "def removeEdges2Liders(implicit_edges, liderLst):\n",
    "    newImplicitEdges = []\n",
    "    for i in range(0,len(implicit_edges)):\n",
    "        newEdges = []\n",
    "        for j in range(0,len(implicit_edges[i])):\n",
    "            if ((implicit_edges[i][j][0] == 0)  and (implicit_edges[i][j][1] in liderLst[i])):\n",
    "#            if ((implicit_edges[i][j][0] in liderLst[i])  and (implicit_edges[i][j][1] in liderLst[i])):\n",
    "                continue\n",
    "            else:\n",
    "                newEdges.append(implicit_edges[i][j])\n",
    "        newImplicitEdges.append(newEdges)\n",
    "                \n",
    "    return (newImplicitEdges)\n",
    "\n",
    "def addImpEdgesRevers(implicit_edges):\n",
    "    \n",
    "    for i in range(0,len(implicit_edges)):\n",
    "        reversed_edges = [edges[::-1] for edges in implicit_edges[i]]\n",
    "        implicit_edges[i].extend(reversed_edges)\n",
    "    return (implicit_edges)\n",
    "        \n",
    "    \n",
    "implicit_edges = removeLoops(implicit_edges)\n",
    "implicit_edges = removeEdges2Liders(implicit_edges, liderLst)\n",
    "#implicit_edges = addImpEdgesRevers(implicit_edges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Hierarchical Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCreateGraphs(posts_topicId,explicit_edges,implicit_edges,liderLst,participanteLst):\n",
    "    graphLst = []\n",
    "    for i in range(0,len(posts_topicId)):\n",
    "        G = nx.DiGraph()\n",
    "        G.add_nodes_from(list(merge(liderLst[i],participanteLst[i])))\n",
    "        G.add_edges_from(explicit_edges[i])\n",
    "        G.add_edges_from(implicit_edges[i])\n",
    "        graphLst.append(G)\n",
    "    return(graphLst)\n",
    "\n",
    "graphLst = getCreateGraphs(posts_topicId,explicit_edges,implicit_edges,liderLst,participanteLst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contar as ligações do nós líderes e participantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes_connections(graphLst,liderLst,participanteLst):\n",
    "    liderConLst = []\n",
    "    participantConLst = []\n",
    "    for i in range(0,len(graphLst)):\n",
    "        degree = graphLst[i].out_degree()\n",
    "        liderCon = []\n",
    "        participantCon = []\n",
    "        for node in liderLst[i]:\n",
    "            liderCon.append(degree[node])\n",
    "        for node in participanteLst[i]:\n",
    "            participantCon.append(degree[node])\n",
    "        liderConLst.append(liderCon)\n",
    "        participantConLst.append(participantCon)\n",
    "    return(liderConLst,participantConLst)\n",
    "\n",
    "liderConLst,participantCon  = get_nodes_connections(graphLst,liderLst,participanteLst)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificar forum em Instructor-Centered ou Synergistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forum_class(posts_topicId,liderConLst,participantCon):\n",
    "    forumClass = []\n",
    "    for i in range(0,len(posts_topicId)):\n",
    "        if (sum(liderConLst[i]) > sum(participantCon[i])):\n",
    "            forumClass.append('Instructor-Centered')\n",
    "        else:\n",
    "            if (sum(liderConLst[i]) < sum(participantCon[i])):\n",
    "                forumClass.append('Synergistic')\n",
    "            else:\n",
    "                forumClass.append('Developing-Synergism')\n",
    "                \n",
    "    return(forumClass)\n",
    "forumClass = get_forum_class(posts_topicId,liderConLst,participantCon)          \n",
    "#forumClass\n",
    "# graphLst[1].degree()\n",
    "# labels = dict(zip(range(0,len(posts_topicId[1]['postUserId'].tolist())),posts_topicId[1]['postUserId'].tolist()))\n",
    "# degree = graphLst[1].degree()\n",
    "# #participanteLst[1]\n",
    "#print(sum(liderConLst[1]),sum(participantCon[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificar forum como Scattered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disconnectedGraphs(graphLst):\n",
    "    scattered =[]\n",
    "    for graph in graphLst:\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(graph.edges())\n",
    "        scattered.append(nx.is_connected(G))\n",
    "    return (scattered)\n",
    "def get_forum_scattered(forumClass,scattered):\n",
    "    for i in range(0,len(scattered)):\n",
    "        if (scattered[i]== False):\n",
    "            forumClass[i] = 'Scattered'\n",
    "    return (forumClass)\n",
    "scattered = get_disconnectedGraphs(graphLst)\n",
    "forumClass = get_forum_scattered(forumClass,scattered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter porcentagens do phaseId e gera planilha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphInfo(liderConLst,participantCon):\n",
    "    liderDegreeSum = []\n",
    "    participantDegreeSum =[]\n",
    "    liderLen = []\n",
    "    participantLen = []\n",
    "    \n",
    "    for degreeList in liderConLst:\n",
    "        liderDegreeSum.append(sum(degreeList))\n",
    "        liderLen.append(len(degreeList))\n",
    "    for degreeList in participantCon:\n",
    "        participantDegreeSum.append(sum(degreeList))\n",
    "        participantLen.append(len(degreeList))\n",
    "    return (liderDegreeSum,participantDegreeSum,liderLen,participantLen)\n",
    "\n",
    "liderDegreeSum,participantDegreeSum,liderLen,participantLen = getGraphInfo(liderConLst,participantCon)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFreqLstDf(posts_topicId):\n",
    "    df = pd.DataFrame(columns=[0,1,2,3,4])\n",
    "    for i in range(0,len(posts_topicId)):\n",
    "        #freq = posts_topicId[i]['phaseId'].value_counts(normalize=True) * 100\n",
    "        freq = posts_topicId[i]['phaseId'].value_counts()\n",
    "        df.loc[i] = freq  \n",
    "    return (df)\n",
    "\n",
    "\n",
    "freq_df = getFreqLstDf(posts_topicId)\n",
    "freq_df['Class'] = forumClass\n",
    "freq_df['topicId']= posts['topicId'].unique()\n",
    "freq_df['liderDegreeSum'] = liderDegreeSum\n",
    "freq_df['participantDegreeSum'] = participantDegreeSum\n",
    "freq_df['liderLen'] = liderLen\n",
    "freq_df['participantLen'] = participantLen\n",
    "\n",
    "freq_df.to_csv(\"final3_090.csv\")\n",
    "\n",
    "#freq_df[[0,1,2,3,4]] = freq_df[[0,1,2,3,4]].apply(pd.to_numeric)\n",
    "#freq_df.head()\n",
    "#posts_topicId[0]['phaseId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq_df[freq_df[4].isna()]\n",
    "#graphLst[0].in_degree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STOP HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerar imagens dos grafos de todos os Fórums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genGraphImages(posts_topicId, graphLst, implicit_edges, explicit_edges, liderLst, participanteLst):\n",
    "    \n",
    "    for i in range(0,len(posts_topicId)):\n",
    "        print(i)\n",
    "        labels = dict(zip(range(0,len(posts_topicId[i]['postUserId'].tolist())),posts_topicId[i]['postId'].tolist()))\n",
    "        graphLst[i].remove_edges_from(implicit_edges[i])\n",
    "        pos=nx.fruchterman_reingold_layout(graphLst[i])\n",
    "        plt.figure(3,figsize=(10,10)) \n",
    "\n",
    "\n",
    "        nx.draw_networkx_nodes(graphLst[i], pos, nodelist=liderLst[i],\n",
    "                               node_color='r', node_size=700, alpha=0.2, with_labels=True)\n",
    "\n",
    "        nx.draw_networkx_nodes(graphLst[i], pos, nodelist=participanteLst[i],\n",
    "                               node_color='g', node_size=700, alpha=0.2, with_labels=True)\n",
    "        if 0 in liderLst[i]:\n",
    "            nx.draw_networkx_nodes(graphLst[i], pos, nodelist=[0],\n",
    "                               node_shape='s',node_color='r', node_size=900, alpha=0.2, with_labels=True)\n",
    "        else:\n",
    "            nx.draw_networkx_nodes(graphLst[i], pos, nodelist=[0],\n",
    "                               node_shape='s',node_color='g', node_size=900, alpha=0.2, with_labels=True)\n",
    "\n",
    "        # # edges\n",
    "        nx.draw_networkx_edges(graphLst[i], pos, edgelist=explicit_edges[i],\n",
    "                                width=1, edge_color = 'b')\n",
    "        nx.draw_networkx_edges(graphLst[i], pos, edgelist=implicit_edges[i],style='dashed',\n",
    "                                alpha=0.5,  arrows=True, edge_color='y')\n",
    "        # # labels\n",
    "        nx.draw_networkx_labels(graphLst[i], pos, labels, font_size=12, font_family='sans-serif')\n",
    "        plt.legend()\n",
    "        plt.axis('off')\n",
    "        plt.savefig('output/'+ \"final3_090_\" + str(i)+ '.png', format=\"PNG\")\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "genGraphImages(posts_topicId, graphLst, implicit_edges, explicit_edges, liderLst, participanteLst)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
